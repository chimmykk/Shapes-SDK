import fs from "fs";
import path from "path";
import { createShapesClient } from "./client";
import { shapes_client } from "../helper/shapeClient";

function getMimeType(filePath: string): string {
  const ext = path.extname(filePath).toLowerCase();
  switch (ext) {
    case ".mp3": return "audio/mpeg";
    case ".wav": return "audio/wav";
    case ".ogg": return "audio/ogg";
    case ".m4a": return "audio/mp4";
    default: throw new Error(`Unsupported audio format: ${ext}`);
  }
}

function coreAnalyzeAudio(client: ReturnType<typeof createShapesClient>, model: string) {
  return async (
    audioPath: string,
    promptText = "Please transcribe and respond to this audio message."
  ) => {
    const buffer = fs.readFileSync(audioPath);
    const base64 = buffer.toString("base64");
    const mimeType = getMimeType(audioPath);
    const audioDataUrl = `data:${mimeType};base64,${base64}`;

    const res = await shapes_client.chat.completions.create({
      model,
      messages: [
        {
          role: "user",
          content: [
            { type: "text", text: promptText },
            { type: "audio_url", audio_url: { url: audioDataUrl } } as any, 
          ],
        },
      ],
    });

    return res.choices[0].message.content;
  };
}

export function createAnalyzeAudio(
  client: ReturnType<typeof createShapesClient>,
  defaultModel = "shapesinc/tenshi"
) {
  const analyzeAudio = async (
    audioPath: string,
    promptText?: string,
    model = defaultModel
  ) => coreAnalyzeAudio(client, model)(audioPath, promptText);

  analyzeAudio.model = new Proxy(
    {},
    {
      get(_, modelName: string) {
        return coreAnalyzeAudio(client, modelName);
      },
    }
  ) as {
    (audioPath: string, promptText?: string, model?: string): Promise<string>;
    model: { [key: string]: (audioPath: string, promptText?: string) => Promise<string> };
  };

  return analyzeAudio;
}
