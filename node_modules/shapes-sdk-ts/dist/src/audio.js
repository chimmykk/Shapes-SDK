"use strict";
var __importDefault = (this && this.__importDefault) || function (mod) {
    return (mod && mod.__esModule) ? mod : { "default": mod };
};
Object.defineProperty(exports, "__esModule", { value: true });
exports.createAnalyzeAudio = createAnalyzeAudio;
const fs_1 = __importDefault(require("fs"));
const path_1 = __importDefault(require("path"));
const shapeClient_1 = require("../helper/shapeClient");
function getMimeType(filePath) {
    const ext = path_1.default.extname(filePath).toLowerCase();
    switch (ext) {
        case ".mp3": return "audio/mpeg";
        case ".wav": return "audio/wav";
        case ".ogg": return "audio/ogg";
        case ".m4a": return "audio/mp4";
        default: throw new Error(`Unsupported audio format: ${ext}`);
    }
}
function coreAnalyzeAudio(client, model) {
    return async (audioPath, promptText = "Please transcribe and respond to this audio message.") => {
        const buffer = fs_1.default.readFileSync(audioPath);
        const base64 = buffer.toString("base64");
        const mimeType = getMimeType(audioPath);
        const audioDataUrl = `data:${mimeType};base64,${base64}`;
        const res = await shapeClient_1.shapes_client.chat.completions.create({
            model,
            messages: [
                {
                    role: "user",
                    content: [
                        { type: "text", text: promptText },
                        { type: "audio_url", audio_url: { url: audioDataUrl } },
                    ],
                },
            ],
        });
        return res.choices[0].message.content;
    };
}
function createAnalyzeAudio(client, defaultModel = "shapesinc/tenshi") {
    const analyzeAudio = async (audioPath, promptText, model = defaultModel) => coreAnalyzeAudio(client, model)(audioPath, promptText);
    analyzeAudio.model = new Proxy({}, {
        get(_, modelName) {
            return coreAnalyzeAudio(client, modelName);
        },
    });
    return analyzeAudio;
}
